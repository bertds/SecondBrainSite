<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://bertds.github.io/SecondBrainSite/">Second Brain</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><h2 id="gradient-boosting">Gradient Boosting</h2>

<p><em>Recall : <a href="q-decision-tree-ensemble-methods.html">Q Decision Tree Ensemble Methods</a></em></p>

<p><img src="gradient_boosting.png" alt="gradient_boosting.png" /></p>

<p>Gradient boosting is een ensemble learning method voor regressie en classificatie problemen. Het resultaat is een predictie model in de vorm van een ensemble van zwakke predicitie modellen (meestal decision trees).</p>

<p>Het basisprincipe is dat het volgende model de tekortkoming van het vorig model zal compenseren. Geijkaardig aan <a href="adaboost-adaptive-boosting-.html">AdaBoost (Adaptive Boosting)</a> maar manier waarop de modellen getraind worden is verschillend :</p>

<p><img src="gradient_boostingvb.png" alt="gradient_boostingvb.png" /><br />
het eerste decision tree model wordt getraind op 60% van de trainingset. Men doet alle voorspellingen voor de volledige trainingsset met dat model en maakt een vector met het verschil tss het voorspelde en de gelabelde waarde (= afwijkingen).<br />
Het volgende model gaat nu obv dezelfde trainingsset als targetwaarde de afwijkingen van dit eerste model krijgen.<br />
Ook de daaropvolgende modellen krijgen de afwijkingen van het model ervoor. </p>

<p>De uiteindelijke predicties van een testset gebeuren dan door het eerste model een predictie te laten doen, het resultaat daarvan af te geven aan het volgende model. Dat model een predictie te laten doen enzovoort.<br />
Het eindresultaat is dan de som van alle predicties. (6.5 in het vb)</p>

<p>deze manier van trainen is nog geoptimaliseerd met als resultaat <a href="xgboost.html">XGBoost</a></p>

<p><code>GradientBoostingClassifier()</code><br />
    learningrate = 0.8 : voting power van de volgende modellen wordt steeds kleiner. deze modellen wegen steeds minder sterk door in het eindresultaat. hierdoor kan je <span class="tag">overfitting</span> tegen gaan. </p>

<p><img src="gradient_boosting_vb.png" alt="gradient_boosting_vb.png" /></p>
</div>

      <div class="backlinks">

<ul>
<li><a href="decision-tree-ensemble-methods.html">Decision Tree Ensemble Methods</a></li>
</ul>

</div>


    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
