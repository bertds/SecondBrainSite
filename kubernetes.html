<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://bertds.github.io/SecondBrainSite/">Second Brain</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><h1 id="kubernetes">Kubernetes</h1>

<h2 id="what-is-kubernetes">What is Kubernetes ?</h2>

<ul>
<li>Open Source container<em>* orchestration tool</em>*</li>
<li>Helps manage containerized applications in <strong>different deployment environments</strong> (VM, cloud, ... )</li>
<li>Service discovery and load balancing</li>
<li>Automated rollouts and rollbacks</li>
<li>Self-healing</li>
<li>Auto scaling</li>
<li>Storage orchestration</li>
</ul>

<h3 id="why-do-we-need-container-orchestration-tools">Why do we need container orchestration tools ?</h3>

<ul>
<li>Trend from <strong>Monolith</strong> to <strong>Microservices</strong></li>
<li>Increased usage of containers</li>
<li>Demand for a proper way of managing those hunderds of containers</li>
</ul>

<h3 id="what-features-do-orchestration-tools-offer">What features do orchestration tools offer ?</h3>

<ul>
<li>High <strong>availability</strong> or no downtime</li>
<li><strong>Scalability</strong> (up and down depanding on the demand) or high performance</li>
<li><em>* Disaster recovery</em>* - backup and restore (application can restart from restored data)<br />
<h2 id="architecture">Architecture</h2></li>
</ul>

<p><img src="Pasted image 20211114130216.png" alt="Pasted image 20211114130216.png" /><br />
Master Node &gt; Worker nodes (different  containers from application deployed/running)<br />
Worker Nodes have most resources, high workload<br />
Master node is more important than worker node because if you lose worker node you can start up a new one but if master node goes down, you can't access the cluster anymore. That's why in production environment you have at least two masters in Kuberneter cluster. </p>

<h3 id="worker-node">Worker node :</h3>

<ul>
<li>Kubelet proces runs on (worker) node :<br />
<ul><br />
<li>needed for communication within the cluster</li><br />
<li>scheduler on worker node itself : starting/stopping/maintaining application container with instructions from the controle plane</li><br />
<li>collects performance and health information of node, pods and containers</li><br />
</ul></li>
<li>Kube-proxy<br />
<ul><br />
<li>Network proxy</li><br />
<li>Manages virtual IP addresses of pods/services</li><br />
<li>works as load balancer for services running on a node</li><br />
</ul></li>
<li>Pod<br />
= running application container </li>
</ul>

<p>*<span class="tag">todo</span> is control plane multiple master nodes or are there multiple control planes ? *</p>

<h3 id="master-node-control-plane">Master node = Control Plane</h3>

<p>(different kubernetes processes : )</p>

<ul>
<li>API server : entrypoint to K8s cluster, all nodes (worker and master) are linked to this API and use it to communicate </li>
<li>Controller Manager : keeps track of whats happening in the cluster : cluster needs repair, cluster restart needed, ... and registers nodes. </li>
<li>Scheduler :<br />
<ul><br />
<li>ensure Pods placement based on the desired amount</li><br />
<li>decides on which node the next container should be scheduled on based on available resources in the node and the needed resources for that container</li><br />
</ul></li>
<li>ectd :<br />
<ul><br />
<li>persistant and distributed key-value data store</li><br />
<li>Kubernetes backing store</li><br />
<li>current state and config of the entire cluster (node/...)</li><br />
<li>backup restore is done using etcd snapshots</li><br />
</ul></li>
<li>Virtual Network : turns all the nodes in one unified machine</li>
</ul>

<h3 id="kubernetes-objects">Kubernetes Objects</h3>

<p>= persistent entities in K8s system.<br />
These entities represent state of your cluster :</p>

<ul>
<li>what containerized applications are running (and on which node)</li>
<li>resources available to those applications</li>
<li>policies around how those applications behave, such as restart policies, upgrades, fault-tolerance<br />
<strong>Kubernetes Object</strong> = record of intent - once created the Kubernetes system will constantly work to ensure that object exists. You're telling the K8s system what you want the cluster's workload to look like; this is your cluster's <strong>desired state</strong>.</li>
</ul>

<h2 id="what-are-the-main-kubernetes-components">What are the main Kubernetes Components ?</h2>

<p><img src="Kubernetes_Components.png" alt="Kubernetes_Components.png" /></p>

<h3 id="pod">Pod :</h3>

<ul>
<li><strong>smallest</strong> unit in Kubernetes</li>
<li>creates a layer around the container, you only communicate with the Kubernetes layer</li>
<li>Usually <em>*1 application *</em>per pod</li>
<li>each Pod get its own IP address (private IP)</li>
<li><strong>Pods are ephemeral !</strong> </li>
<li><p><strong>New IP-address on re-creation</strong> (if you communicate using IP addresses you have to change it everytime Pod crashes/restarts)</p>

<h3 id="service-and-ingress">Service and Ingress :</h3></li>
<li><p>When program element needs to make use of the functions abstracted by the Service, it makes a request to the service, rather than an individual pod. The Service acts as a dispatcher, assigning a pod to handle the request. </p></li>
<li>Service is also a loadbalancer and checks which pod (if is duplicated) has less load and can process the new request</li>
<li><strong>Permanent</strong> IP address attached to Pod</li>
<li>Lifecycle of Pod and Service are not connected (IP Address Pod stays when crashes/restarts)</li>
<li>set of Pods targeted by a Service is (usually) determined by <strong>Label Selector</strong></li>
<li>Type of service :<br />
<ul><br />
<li><strong>External</strong> Service : connect to outside sources without opening own application to it</li><br />
<li><strong>Internal</strong> Service : default type</li><br />
</ul></li>
<li>Ingress<br />
<ul><br />
<li>External Service gives unsecure IP address &gt; you need <strong>Ingress</strong> to make it <strong>secure</strong> and use a <strong>webaddress</strong> instead of a IP address</li><br />
<li>Routes traffic based on request rules configured</li><br />
<li>Deploy a Controller (like nginx)</li><br />
<li>Deploy Resources</li><br />
<li>(tip : use Rancher to deploy Ingress Controllers and Resources with it's UI)</li><br />
<li>diffcult to setup in howest context with it's firewalls. </li><br />
</ul></li>
</ul>

<p><strong>A client never connects to a container, but to a Pod, through a Service.</strong></p>

<h3 id="configmap-and-secret">ConfigMap and Secret :</h3>

<p><img src="Pasted image 20211114122815.png" alt="Pasted image 20211114122815.png" /><br />
 External Configuration of your application with</p>

<ul>
<li>ConfigMap :<br />
<ul><br />
<li>Is for <strong>non-confidential</strong> data only ! (not secure for passwords)</li><br />
</ul></li>
<li>Secret :<br />
<ul><br />
<li>used to store secret data</li><br />
<li>stored in base64</li><br />
<li>encryption should be done by third party tools in Kubernetes</li><br />
</ul></li>
<li>Decouple config from hard-coded environment variables </li>
<li>You can use ConfigMap/Secret info as environment variables/properties file</li>
<li>example:<br />
<ul><br />
<li>different config for dev, staging, prod environment</li><br />
<li>storing passwords and using it in your applications</li><br />
</ul></li>
</ul>

<h3 id="volume">Volume</h3>

<p>Data storage<br />
If db data is stored on pod than data is lost when pod crashes<br />
Connects physical storage (local or external remote/cloud  storage - outside kubernetes cluster) to your pod<br />
<strong>Kubernetes doesn't manage data persistance!</strong></p>

<ul>
<li>PersistentVolumes<br />
<ul><br />
<li>define a storage volumes in the cluster</li><br />
<li>Independent lifecycle</li><br />
<li>otherwise : ephemeral data inside the pods (= if pod dies, data is gone)</li><br />
</ul></li>
<li>PersistentVolumeClaims<br />
<ul><br />
<li>Requests to obtain acess to a PersistentVolume</li><br />
<li>Volumes will be mounted to a pod</li><br />
</ul></li>
</ul>

<h3 id="deployment-statefulset">Deployment &amp; StatefulSet</h3>

<p><img src="Pasted image 20211114123921.png" alt="Pasted image 20211114123921.png" /><br />
To have no downtime (if application pod crashes/unavailable) node are duplicated but are linked to same service. Pod are duplicated using blueprints and you specify how many replicas you want to run. </p>

<ul>
<li>In practice you don't work with pods but with Deployments. </li>
<li>Deployments are abstraction of Pods </li>
<li>Deployment is a YAML object</li>
<li>with Deployments you can define how many duplicates (replicas) you want running based on blueprint of Pod. </li>
<li>you define the number of replicas you want to have running in the cluster via a <strong>ReplicaSet</strong> (which is part of the deployment object)</li>
<li><strong>DaemonSets</strong>  ensure that all (or some) Nodes run a copy of a Pod.<br />
As nodes are added to the cluster, Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created. example: cluster storage daemon (glusterd, ceph) on each node, logs collection daemon one every node (fluentd, filebeat)</li>
<li><strong>DB can't be replicated via Deployments !</strong> &gt; because DB has state (=data)<br />
StatefulSet is for replication of DB/StateFUL applications (Mongodb, MySQL, ...)<br />
In practice DB are often hosted outside of Kubernetes Cluster because it isn't easy to setup. </li>
</ul>

<p><span class="tag">todo</span> difference replicaset vs daemonset</p>

<h3 id="load-balancer">Load balancer</h3>

<p><img src="Pasted image 20211114182629.png" alt="Pasted image 20211114182629.png" /></p>

<ul>
<li>L4 (TCP)<br />
<ul><br />
<li>Only available on Cloud Providers</li><br />
</ul></li>
<li>L7 Load balancing<br />
<ul><br />
<li>Ingress = load balancing option Kubernetes provides</li><br />
<li>Can redirect traffic to specific workloads based on request</li><br />
</ul></li>
</ul>

<h3 id="kube-proxy">Kube-proxy</h3>

<ul>
<li>(small) load distribution</li>
<li>default : randomly route to Ip address based on iptables</li>
</ul>

<h3 id="autoscaler-hpa-horizontal-pod-autoscaler">Autoscaler - HPA - horizontal pod autoscaler</h3>

<p><img src="Pasted image 20211114183400.png" alt="Pasted image 20211114183400.png" /></p>

<ul>
<li>min and max number of replicas</li>
<li>metric to monitor and base scaling decisions on, such as CPU usage</li>
<li>HPA checks every 30 seconds</li>
</ul>

<h2 id="setting-up-kubernetes-cluster">Setting up Kubernetes Cluster</h2>

<p><img src="Pasted image 20211114125527.png" alt="Pasted image 20211114125527.png" /><br />
In the configuration you tell what you want and Kubernetes tries to meet those requirements.<br />
<img src="Pasted image 20211114125606.png" alt="Pasted image 20211114125606.png" /><br />
Deployment and Service Configuration file :</p>

<ul>
<li>apiversion : which version of the Kubernetes API you're using to create this object</li>
<li>kind : what kind of object you want to create</li>
<li>metadata : data that helps uniquely identiy the object (name string, UID, optional namespace)</li>
<li>specification : what state you desire for the object<br />
<ul><br />
<li>attributes of spec are specific to the kind of component</li><br />
<li>spec &gt; selector &gt; matchLabels should be the same as spec &gt; template &gt; metadata &gt; labels</li><br />
<li>replicas : amount of pods to start up with this template</li><br />
</ul></li>
<li>status &gt; <strong>automatically generated and added by Kubernetes</strong><br />
<img src="Pasted image 20211114184441.png" alt="Pasted image 20211114184441.png" /></li>
</ul>

<p>K8s  compares status constantly &gt; if difference takes action<br />
Where does K8S get status data ?<br />
    <img src="Pasted image 20211114125940.png" alt="Pasted image 20211114125940.png" /><br />
    K8s gets it from etcd which holds current status of any K8s component.</p>

<p>Format of the configuration file = yaml &gt; store the config files with your code (or own git repo for config files)</p>

<h2 id="helm">Helm</h2>

<h3 id="what-is-helm">What is Helm ?</h3>

<ul>
<li><p><strong>Helm</strong> is an application <strong>package management registry for Kubernetes</strong>.<br />
To package YAML files and distribute them in public and private repositories.</p></li>
<li><p><strong>Helm charts</strong> are pre-configured software application resources you can download (Helm repository) and deploy in your Kubernetes environment. (= bundle of YAML files) <strong>You can create custom Helm charts.</strong><br />
You can (re)use existing Helm Charts for Database Apps (Mongodb, ElasticSearch, ...) or Minitoring Apps (Prometheus)<br />
<img src="Pasted image 20211114184935.png" alt="Pasted image 20211114184935.png" /></p></li>
</ul>

<p>How to look for Helm charts ? </p>

<ul>
<li><code>helm search &lt;keyword&gt;</code></li>
<li>Helm hub: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbWRXcEU3eHJGMlZlUjRESlFQTkhyazRZaXhHQXxBQ3Jtc0tsbURqeEQ3UG9Yc2FVcWowMTlFcHM0NjFNU2NFcGFqdFM1a09HUW8xbjNqb2lmb19iYjhOeml1WGpyMm0xNUpBbmthZGlVblJKaTVzYW95c282RlZ5QjhVZnMtbnB3ZmxNMGs1bVlyUnA5VE9fdlhHbw&amp;q=https%3A%2F%2Fhub.helm.sh%2F">https://hub.helm.sh/</a> </li>
<li>Helm charts GitHub Project: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbURkdkcxallnekpOXzZuWjAwR3czYnI2N09Fd3xBQ3Jtc0trNl9MbDBFLVFaNW9xR0pqQU5kR1cyaGJFS3lFNlREX0lCS1VsRm1SaVBVbVdvQVVKdVEwcXNJZDVJdWUyeFVqV1lGREphdXMxbFNaQmJTQ0FFZXlZcGFJNEkyVEtLbHhhNWt3WFd3SkFfWXNVbDVBRQ&amp;q=https%3A%2F%2Fgithub.com%2Fhelm%2Fcharts">https://github.com/helm/charts</a></li>
</ul>

<h3 id="features">Features</h3>

<h4 id="templating-engine">Templating Engine</h4>

<ul>
<li>define a common blueprint</li>
<li>dynamic {{values}} in template file are replaced by placeholders </li>
<li>advantage :<br />
<ul><br />
<li>you have less yaml files to maintain</li><br />
<li>Practical for CI/CD : In your build you can replace the values on the fly<br /><br />
<img src="Pasted image 20211115102042.png" alt="Pasted image 20211115102042.png" /><br /><br />
<img src="Pasted image 20211115102122.png" alt="Pasted image 20211115102122.png" /></li><br />
</ul></li>
</ul>

<p>Use Case for Helm features : deploy same applications accross different environments (dev, staging, production).<br />
<img src="Pasted image 20211115102325.png" alt="Pasted image 20211115102325.png" /></p>

<h4 id="helm-chart-structure">Helm Chart Structure</h4>

<p><img src="Pasted image 20211115102439.png" alt="Pasted image 20211115102439.png" /><br />
<code>helm install &lt;chartname&gt;</code></p>

<h4 id="value-injection-into-template-files">Value injection into template files</h4>

<p><img src="Pasted image 20211115102636.png" alt="Pasted image 20211115102636.png" /><br />
You can change values using a my-values.yaml file<br />
<img src="Pasted image 20211115102705.png" alt="Pasted image 20211115102705.png" /><br />
You can also change it manually in the command line<br />
<img src="Pasted image 20211115102717.png" alt="Pasted image 20211115102717.png" /></p>

<h4 id="release-management">Release management</h4>

<h5 id="v2">V2</h5>

<p>Client (Helm CLI) - Server (Tiller)<br />
When you <code>helm install chart</code> the client will send the requests to Tiller.<br />
Tiller will store all versions of the helm chart. The changes are applied to existing deployment instead of creating a new one.<br />
You can also rollback the upgrade (<code>helm rollback.</code>)<br />
<img src="Pasted image 20211115102811.png" alt="Pasted image 20211115102811.png" /><br />
<img src="Pasted image 20211115102909.png" alt="Pasted image 20211115102909.png" /><br />
Downside of Tiller :</p>

<ul>
<li>Tiller has too much power inside of K8s cluster (create, delete, update components) &gt; too much permissions</li>
<li>Security issue</li>
</ul>

<h5 id="v3">V3</h5>

<p><strong>Tiller is removed</strong> because of security issue in V2<br />
<img src="Pasted image 20211115103031.png" alt="Pasted image 20211115103031.png" /></p>

<h2 id="rancher">Rancher</h2>

<h3 id="what-is-rancher">What is Rancher ?</h3>

<p>Rancher is a complete software stack for teams adopting containers.<br />
It addresses operational and security challengers for managing multiple Kubernets clusters, while providing DevOps teams with integrated tools for running containerized workloads. </p>

<ul>
<li>simple/intuitive UI to get started with Kubernetes</li>
<li>multi-cloud and hybrid-cloud Kubernetes solutions</li>
<li>fast way to set up on-premises Kubernetes clusters</li>
<li>includes CI/CD pipelines for DevOps operations<br />
<img src="Pasted image 20211115104504.png" alt="Pasted image 20211115104504.png" /></li>
</ul>

<h2 id="minikube-and-kubectl">Minikube and Kubectl</h2>

<p>How to test on local machine ? With Minikube where master and worker processes work on one node with docker container preinstalled.<br />
Kubectl = command line tool for K8s which communicates through API server of the K8s cluster</p>

<p>How to get own application in Kubernetes<br />
<img src="Pasted image 20211114131909.png" alt="Pasted image 20211114131909.png" /><br />
<img src="Pasted image 20211114132617.png" alt="Pasted image 20211114132617.png" /></p>

<h2 id="what-we-learned">What we learned</h2>

<p><img src="Pasted image 20211115104516.png" alt="Pasted image 20211115104516.png" /></p>
</div>

      

    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
