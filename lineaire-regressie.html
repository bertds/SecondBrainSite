<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://github.com/bertds">GitHub</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><h1 id="lineaire-regressie">Lineaire regressie</h1>

<p>Tags: <span class="tag">AI</span><br />
Date: 2020-11-21<br />
Type: <a href="cursus-topic.html">Cursus topic</a><br />
Related: <!-- Links to pages not referenced in the content --><br />
Source :<br />
Questionds : <a href="q-lineair-regression.html">Q Lineair Regression</a></p>

<h2 id="notities">Notities</h2>

<h4 id="enkelvoudige-linaire-regressie">Enkelvoudige linaire regressie</h4>

<ul>
<li>rechte die het dichtst bij alle punten ligt<br />
<img src="enk_lin_reg_1.png" alt="enk_lin_reg_1.png" /></li>
<li>mbv <a href="kostenfunctie.html">kostenfunctie</a> bepalen welke parameters de beste zijn<br />
<img src="enk_lin_reg_2.png" alt="enk_lin_reg_2.png" /></li>
<li>die parameters zoeken we met <a href="gradient-descent.html">gradient descent</a><br />
<img src="gradient_descent_omega1.png" alt="gradient_descent_omega1.png" /><br />
<img src="gradient_descent_omega2.png" alt="gradient_descent_omega2.png" /></li>
<li><a href="learning-rate.html">learning rate</a> grote stappen is beter dan kleine stappen (dan duurt het lang om het optimaal punt te vinden) maar je kan over je optimaal punt stappen door te grote stappen<br />
<img src="gradient_descent_lokvsgloboptimum.png" alt="gradient_descent_lokvsgloboptimum.png" /><br />
<img src="gradient_descent_learning_rate.png" alt="gradient_descent_learning_rate.png" /></li>
</ul>

<h4 id="meervoudige-lineaire-regressie">Meervoudige lineaire regressie</h4>

<ul>
<li>het model/hypothese wordt bepaald aan de hand van een trainingset met <strong>meerdere features</strong></li>
<li><a href="stappenplan-dataanalyse.html">stappenplan dataanalyse</a><br />
<ul><br />
<li>consistentie van de dataset<br /><br />
<ul><br /><br />
<li>volledigheid van de dataset</li><br /><br />
<li>inconsistenties</li><br /><br />
<li>spreiding van de gegevens</li><br /><br />
</ul></li><br />
<li>statistische voor analyse<br /><br />
<ul><br /><br />
<li>uitschieters<br /><br /><br />
<ul><br /><br /><br />
<li>verwijderen van extreme waarden/samples</li><br /><br /><br />
<li>geavanceerde technieken (bij clustering)</li><br /><br /><br />
</ul></li><br /><br />
<li>onderlinge correlaties zoeken mbv <a href="heatmap.html">heatmap</a> :<br /><br /><br />
<ul><br /><br /><br />
<li>+1: linair verband tss features ene omhoog en andere omhoog</li><br /><br /><br />
<li>-1 : lineair verband tss features ene omhoog en andere omlaag</li><br /><br /><br />
</ul></li><br /><br />
<li>verhoudig tss features bekijken via <a href="pairplot.html">pairplot</a>:</li><br /><br />
</ul></li><br />
<li>dataset opsplitsen in features en targets</li><br />
<li>data opsplisten in training en testset:<br /><br />
<ul><br /><br />
<li>randomize om alle cases te kunnen trainen</li><br /><br />
<li>soms geen randomize mogelijk omdat volgorde van belang is (tijdreeks)</li><br /><br />
</ul></li><br />
<li>testen van het model: (hiermee kunnen modellen vergeleken worden)<br /><br />
<ul><br /><br />
<li><a href="mae.html">MAE</a> mean absolute error<br /><br /><br />
$MAE = \dfrac{1}{n}\sum^n_{i=1}|y_i - \hat{y_i}|$<br /><br /><br />
is het gemiddelde van de absolute waarden van het verschil tss de werkelijke waarden $y_i$ en de voorspelde waarden $\hat{y_i}$</li><br /><br />
<li><a href="mse.html">MSE</a> mean squared error<br /><br /><br />
$MSE = \dfrac{1}{n}\sum^n_{i=1}(y_i - \hat{y_i})^2$<br /><br /><br />
is het gemiddelde van de gekwadrateerde waarden van het verschil tss de werkelijke waarden $y_i$ en de voorspelde waarden $\hat{y_i}$<br /><br /><br />
-> hiermee gaan extreme cases slechter laten scoren</li><br /><br />
<li><a href="r2.html">R2</a> determinatiecoëfficient<br /><br /><br />
$R^2 = 1 - \dfrac{\sum^n_{i=1}(y_i - \hat{y_i})^2}{\sum^n_{i=1}(y_i - \bar{y})^2}$<br /><br /><br />
zegt hoeveel van de variabiliteit verklaard wordt door het model. Perfecte voorspelling is $R^2$ = 1<br /><br /><br />
Een negavtieve waarde voor $R^2$ betekent dat het model slechter scroot dan een horizontale lijn ($y_i = \bar{y}$)<br /><br /><br />
-> score zo dicht mogelijk bij 1</li><br /><br />
</ul></li><br />
</ul></li>
</ul>

<h4 id="feature-engineering">Feature Engineering</h4>

<h5 id="normalisatie-features-op-dezelfde-schaal-brengen-scalersscalershtml">normalisatie = features op dezelfde schaal brengen <a href="scalers.html">scalers</a></h5>

<p>-> Gradient Descent convergeert minder snel als features op een verschillende schaalgrootte staan</p>

<h6 id="min-max-scaler">min-max scaler</h6>

<p><img src="minmax_scaling_ex.png" alt="minmax_scaling_ex.png" /></p>

<ul>
<li>schaalt alle features tss 0 en 1</li>
<li>werkt goed bij niet Gaussiaanse distributires en bij kleine variantie</li>
<li>de scheefheid (skew) blijft bewaard</li>
<li>gevoelig voor uitschieters</li>
</ul>

<h6 id="standard-scaler">standard scaler</h6>

<p><img src="standaardscaler_ex.png" alt="standaardscaler_ex.png" /></p>

<ul>
<li>Geschaalde features:gemiddelde = 0 en standaardafwijking = 1.</li>
<li>Geschaalde features schommelen rond 0 (soms nodig bij deep learning).</li>
<li>Vervormt geen relatieve afstanden tussen de feature waarden.</li>
<li>Kan beter overweg met uitschieters.</li>
<li>Garandeert geen genormaliseerde data op exact dezelfde schaal.</li>
</ul>

<h6 id="robust-scaler">robust scaler</h6>

<p><img src="robust_scaler_ex.png" alt="robust_scaler_ex.png" /></p>

<ul>
<li>Lijkt op MIN-MAX scaler maar gebruikt de interkwartielafstand ipv range.</li>
<li>Houdt geen rekening met uitschieters.</li>
<li>Gebruikt minder data bij het bepalen van de schaal.</li>
<li>Range van de genormaliseerde data is groter dan bij MIN-MAX scaling.</li>
<li>Garandeert geen genormaliseerde data op exact dezelfde schaal.</li>
</ul>

<h5 id="nieuwe-features-toevoegen">nieuwe features toevoegen</h5>

<ul>
<li>manueel kwadraat feature toevoegen</li>
<li>combinatie van features maken</li>
<li>nieuwe feature uit bestaande feature halen (bijv dag van de week uit datum, uit begin en eindpunt afstand halen)</li>
<li><p>nieuwe opgemeten parameters</p>

<h5 id="hogere-orde-features">hogere orde features</h5></li>
<li><p>het verband tss features en target(s) is niet altijd lineair</p></li>
<li><p>feature in kwadraat, tot de 3de, 4de macht<br />
<img src="hogere_orde_feature_graph1.png" alt="hogere_orde_feature_graph1.png" /><br />
<img src="hogere_orde_feature_graph2.png" alt="hogere_orde_feature_graph2.png" /></p>

<h5 id="one-hot-encodingone-hot-encodinghtml"><a href="one-hot-encoding.html">one hot encoding</a>:</h5></li>
<li><p>omzetten van label/categorische variabelen naar meerdere aparte features<br />
<img src="onehot_encoding_ex.png" alt="onehot_encoding_ex.png" /></p></li>
</ul>

<h4 id="underfitting-overfitting">Underfitting, Overfitting</h4>

<ul>
<li><strong>underfitting</strong><br />
<ul><br />
<li>model kan de trainingsdata niet modelleren</li><br />
<li>en ook niet generaliseren op nieuwe data</li><br />
<li>model is te eenvoudig</li><br />
<li>model met een <strong>hoge bias</strong></li><br />
<li>als de R2 score op de trainingset (en testet) slecht is (= slechter scoort dan gewoon gemiddelde van targetwaarde nemen) dan is er sprake van underfitting</li><br />
</ul></li>
<li><strong>overfitting</strong><br />
<ul><br />
<li>model benadert de trainingsdata te goed - scoort heel goed</li><br />
<li>het model kan niet meer generaliseren</li><br />
<li>de <strong>ruis</strong> van de willekeurige fluctuaties in de data wordt opgepikt door het model</li><br />
<li>model met een <strong>hoge variance</strong></li><br />
<li>maar scoort slechter op de testdata</li><br />
<li>model is te complex</li><br />
<li>als er veel features zijn dan is het moeilijker om overfitting te krijgen bij complex model</li><br />
<li>als de R2 score op de trainingset veel beter scoort dan die op de testset  dan is er sprake van overfitting (trainingset score bijna 1 en testset veel lager of zelfs negatief)<br /><br />
(zie ook <a href="lineaire-regressie#regularisatie.html">Regularisatie</a> )</li><br />
</ul></li>
</ul>

<h4 id="opsporen-van-uitschieters">Opsporen van uitschieters</h4>

<p>uitschieters niet altijd te bepalen obv 1 feature op zich maar een combinatie van features (die soms zeer zeldzaam zijn !)</p>

<ul>
<li>naïeve manier:<br />
<ul><br />
<li>uitzonderlijke waarden van 1 feature  &gt; waardoor die ver verwijderd zijn van gemiddelde waarde</li><br />
<li>data kuisen door alles te selecteren binnen de 5 standaardafwijkingen rond het gemiddelde</li><br />
<li>MAAR extreme waarden erin laten indien ze geen gevolg zijn van fouten (sensoren die niet goed waren, type fouten, ...)</li><br />
</ul></li>
</ul>

<h4 id="correlatie-matrix">Correlatie matrix</h4>

<p>X / y<br />
    - positief : positieve correlatie tss feature en gewenst resultaat<br />
    - negatief : negatieve correlatie<br />
! geeft enkel linaire samenhang !<br />
onderlinge correlatie van features &gt; als de ene veranderd zal de andere op voorspelbare manier mee veranderen<br />
als je features zou willen weglaten &gt; kijken naar features die weining invloed hebben op target en die sterke correlatie hebben met andere features</p>

<h4 id="pairplotpairplothtml"><a href="pairplot.html">pairplot</a></h4>

<ul>
<li>indien je veel data hebt een subset nemen omdat het plotten anders lang duurt</li>
<li>histogram op hoofddiagonaal (scatterplot met zichzelf zou rechte lijn geven)<br />
<ul><br />
<li>geeft aan hoe de waarden van dat feature verdeeld zijn<br /><br />
<ul><br /><br />
<li>welke <a href="scaler.html">scaler</a> te gebruiken ?<br /><br /><br />
<ul><br /><br /><br />
<li>normaal &gt; standaard scaler</li><br /><br /><br />
<li>veel uitschieters &gt; robust scaler</li><br /><br /><br />
<li><a href="one-hot-encoding.html">one hot encoding</a> &gt; min max scaler (heel gevoelig aan uitschieters)</li><br /><br /><br />
</ul></li><br /><br />
</ul></li><br />
</ul></li>
<li>andere plots zijn scatterplots</li>
</ul>

<h4 id="coefficient-getraind-model">coeffIcient getraind model</h4>

<ul>
<li>coefficiant = $\theta$ - gewicht van de feature om tot kwaliteitsscore te komen</li>
<li>intercept = $\theta_0$ - constante die altijd aanwezig is</li>
<li>als $\theta_n$ &gt; 0 feature beinvloed target positief</li>
<li>als $\theta_n$ &lt; 0 feature beinvloed target negatief</li>
<li>hogere orde feature toevoegen als lineaire verbanden van features niet gemapt/gekapteerd kunnen worden. hierdoor wel risico dat je complexer model krijgt en dat het dichter bij de trainingsdata gaat aanleunen en je overfitting krijgt.</li>
</ul>

<h4 id="regularisatie">Regularisatie</h4>

<p>Methode om de mate van bias van een hypothese te regelen en een goed evenwicht te vinden tussen underfitting en overfitting. Je kan een extra kostenterm  toevoegen die het gebruik van hogere orde features afstraft tenzij ze de globale kostenfunctie doen dalen.  $+\lambda_1\sum_{j=1}^{n} |\theta_j|$ (als $\theta$ stijgt wordt model afgestraft)<br />
Dit om te vermijden dat het model zich vastrijdt in ruis in de data:</p>

<ul>
<li>Lasso Regression : L1 regularisatie = absolute waarde $\theta$<br />
$J_L1 = \sum^n_{i=1}(target^{(i)} - output^{(i)}) + \lambda_1 \sum^m_{j=1}|\theta_j|$</li>
<li>Ridge Regression : L2 regularisatie = kwadraat van $\theta$ -> extreme waarden worden afgestraft<br />
$J_L2 = \sum^n_{i=1}(target^{(i)} - output^{(i)}) + \lambda_2 \sum^m_{j=1}\theta^2_j$</li>
</ul>

<p>!Opgelet! $\theta_0$ = bias wordt NIET geregulariseerd.<br />
Met $\lambda$ bepaal je hoe hard regularisatie meespeelt ($\lambda$ in scikit learn = $\alpha$)</p>

<ul>
<li>$\alpha$ :<br />
<ul><br />
<li>zeer hoog =&gt; alle $\theta$ worden zeer laag of = 0, hoge bias, lage variantie (underfitting)</li><br />
<li>kleine waarde =&gt;  lage bias, hoge variantie (overfitting)</li><br />
</ul></li>
<li>$R^2$ score = 0 =&gt; model doet het niet beter dan als predictie steeds het gemiddelde zou zijn</li>
<li>welke waarde voor $\alpha$ ?<br />
<ul><br />
<li>bepaling : $\alpha$ laten variëren en $R^2$ score daar tegen zetten =&gt; optimum van $\alpha$ waar $R^2$ voor testset de hoogste waarde heeft</li><br />
</ul></li>
</ul>

<ul>
<li><p>voorbeeld hyperparameter tuning:</p>

<ul>
<li>waarden voor alpha 10000 wijst op underfitting. vooral het feit dat trainingsset slecht scoort wijst hierop.  </li>
<li><p>waarden voor alpha 0.01 wijst op overfitting en L2 score voor test set wijst erop dat het slechter scoort dan de gemiddelde prijs</p>

<table>
<thead>
<tr>
  <th></th>
  <th>$\alpha$  = 10000</th>
  <th>$\alpha$  = 0.01</th>
  <th>$\alpha$  = 20</th>
</tr>
</thead>
<tbody>
<tr>
  <td>R2 score op test L2</td>
  <td>0.29</td>
  <td>-1.31</td>
  <td>0.80</td>
</tr>
<tr>
  <td>R2 score op training L2</td>
  <td>0.29</td>
  <td>0.99</td>
  <td>0.95</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul>
</div>

      <div class="backlinks">

<ul>
<li><a href="ai-home.html">AI@home</a></li>
<li><a href="q-lineair-regression.html">Q Lineair Regression</a></li>
</ul>

</div>


    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
