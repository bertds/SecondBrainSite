<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://bertds.github.io/SecondBrainSite/">Second Brain</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><h1 id="proefexamen-vragen-machine-learning">Proefexamen vragen Machine learning</h1>

<p><a href="anki.html">anki</a></p>

<p>Q: Bespreek twee manieren om overfitting tegen te gaan.<br />
A: de mogelijkheden zijn :</p>

<ul>
<li>meer trainingsdata gebruiken bijv bij NN, model gaat meer gevraieerde data zien, gaat niet zo makkelijk de data vanbuiten kunnen leren</li>
<li>model complexer maken hogere orde features toevoegen</li>
<li>dropouts bij NN</li>
<li>C bijstellen bij Logistic Regression/SVM</li>
<li>bij decision trees overschakelen op RFT</li>
<li>learning rate verlagen (0.8 ipv 0.9) bij Gradient Boosting bij ensemble learning waardoor de invloed van de volgende modellen kleiner wordt en je overfitting voorkomt. </li>
<li>kleinere gamma kiezen bij SVM<br />
<!--ID: 1610897709966--></li>
</ul>

<p>Q: Bespreek het verschil tussen bagging en boosting<br />
A: Bagging en boosting zijn beide ensemble methodes. Beide nemen slechts een random deel van de trainingset (met teruglegging) om een nieuw model te trainen.  Aangezien de modellen bij bagging onafhankelijk van elkaar zijn kunnen de modellen in parallel getraind worden. Indien de modellen voor een bepaalde klasse slecht score gaat bagging hier niets aan veranderen.<br />
Bij boosting echter wordt dit laatste wel opgelost door die data elementen die verkeerd gescoord werden een groter gewicht toe te kennen om geselecteerd te worden voor de bag van het volgende model. Hierop wordt er op die datapunten meer getraind. Het gevolg is dat de accuraatheid van boosting beter is dan bij bagging.<br />
Mogelijk nadeel hierbij kan zijn dat er overfitting optreed omdat het ensemble elk datapunt probeert goed te krijgen en dus ook de ruis van die datapunten meeneemt in de modellen.<br />
Aangezien de kans op selectie na elke training moet bijgesteld worden  kunnen de modellen dus enkel sequentieel getraind worden bij boosting in tegenstelling tot bagging waar dit parallel kon gebeuren.<br />
RFT vb van bagging<br />
Adaboost, XGBoost, GradientBoost als boosting vb<br />
<!--ID: 1610897710123--></p>

<p>Q: Bespreek het verschil tussen regressie en classificatie. Geef van elk een voorbeeld.<br />
A: Bij regressie gaat het model een getal predicten (prijs van een huis) terwijl bij classificatie (hond of kat) het model gaat aangeven hoe waarschijnlijk het is dat de predictie een bepaald label/klasse is. Voor regressie zou je een SVM kunnen gebruiken en bij classificatie een RFT.<br />
<!--ID: 1610897710142--></p>

<p>Q: Bespreek een manier om overfitting op te sporen.<br />
A: bij SVM bereken je de accuracy van je model zowel op trainingset als testset en als die op testset veel lager is dan op de trainingset heb je overfitting.<br />
<!--ID: 1610897710158--></p>

<p>Q: Bespreek het nut van het gebruik van dropout bij neurale netwerken.<br />
A: Om te voorkomen dat een NN gaat overfitten kan je aangeven hoeveel procent dropout er is tijdens de training. Hiermee geef je aan hoeveel procent van de neuronen op non-actief moeten gezet worden tijdens de training. Hierdoor moeten de andere neuronen dit compenseren en gaan ze generieker ingesteld worden en voorkom je overfitting.<br />
<!--ID: 1610897710176--></p>

<p>Q: Wat is er ‘naive’ aan naive Bayes?<br />
A: Bij Naive Bayes hou je geen rekening met de correlatie tss de features/woorden.<br />
<!--ID: 1610897710193--></p>

<p>Q: Welke bewering(en) zijn correct ivm het bag-of-words model bij natural language processing<br />
    1.  Het bag-of-words model houdt rekening met de volgorde van de woorden<br />
    2.  Het bag-of-words model houdt geen rekening met de volgorde van de woorden<br />
    3.  De grootte van de bag-of words hangt af van de grootte van de vocabulair<br />
    4.  De grootte van de bag-of words hangt niet af van de grootte van de vocabulair<br />
A: 2 en 3<br />
<!--ID: 1610789548394--></p>

<p>Q: Een support vector machine werd 3 keer getraind met een RBF kernel, telkens met verschillende gamma waarden. De C-waarde was telkens hetzelfde. Rangschik de onderstaande plots van kleine gamma waarde naar grote gamma waarde.<br />
<img src="SVMgammaquestion.png" alt="SVMgammaquestion.png" /><br />
A: B &lt; A &lt; C<br />
<!--ID: 1610789548517--></p>

<p>Q: Welke van onderstaande activatiefuncties produceren een output die gelegen is tussen -1 en +1:</p>

<ol>
<li>Sigmoid</li>
<li>Tanh</li>
<li>Relu<br />
A: 2<br />
<!--ID: 1610789548530--></li>
</ol>

<p>Q: Een model voorspelt of een tumor al dan niet kwaadaardig is. Na testen van het model bekom je onderstaande confusion matrix.<br />
<img src="confusionmatrixquestion.png" alt="confusionmatrixquestion.png" /><br />
Welke bewering(en) kloppen NIET met betrekking tot deze confusion matrix?</p>

<ol>
<li>De accuraatheid is hoger dan 90%</li>
<li>De recall van klasse ‘No’ is hoger dan die van klasse ‘Yes’</li>
<li>Het aantal false positives is groter dan het aantal false negatives<br />
A: enkel 2<br />
<!--ID: 1610789548541--></li>
</ol>

<p>Q: Gezichtsherkenning is een toepassing van </p>

<ol>
<li>Regressie</li>
<li>Classificatie</li>
<li>Unsupervised learning</li>
<li>Supervised learning<br />
A: 2 en 4<br />
<!--ID: 1610789548548--></li>
</ol>

<p>Q: Veronderstel dat een neuraal netwerk een zeer hoge accuraatheid haalt op de training set maar een slechte op de test set. Welke stappen kan je ondernemen?</p>

<ol>
<li>Meer training data gebruiken</li>
<li>Minder training data gebruiken</li>
<li>Dropout toepassen<br />
A: 1 en 3<br />
<!--ID: 1610789548566--></li>
</ol>
</div>

      <div class="backlinks">

<ul>
<li><a href="ai-home.html">AI@home</a></li>
</ul>

</div>


    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
