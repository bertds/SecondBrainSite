<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://bertds.github.io/SecondBrainSite/">Second Brain</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><h1 id="qa-142021">Q&amp;A 1/4/2021</h1>

<p>Tensorboard te gebruken als je meerdere modellen wil trainen en die onderling wil vergelijken.</p>

<p>Q: Wat is het concept van transferlearning ? Geef een paar voorbelden van transfer learning ?  Wat is het voordeel van transferlearning ?  Waarom zou je het toepassen ? Wanneer niet ?<br />
A: Bij transfer learning neem je een reeds getraind model (de opbouw en parameters) als basis voor je eigen model. Je gaat hierbij enkel de laatste layer hertraining of een extra layer achteraan toevoegen en trainen. De andere parameters hou je ongewijzigd. Het idee hierachter is om, zeker bij grotere NN, trainingstijd, keuze in opbouw, zoeken van trainingsdata uit te sparen en reeds een goed model te hebben waarvan kan vertrokken worden. Je kan bijv OpenCV of YOLO als basis gebruiken om je NN eigen gezichten of objecten te herkennen.<br />
Je haalt echter niet altijd betere resultaten met voorgetrainde modellen. Als je zelf voldoende traningsdata hebt dan kan je eigen model beter scoren dan het hertrainde model. Als je echter weinig data hebt en je eigen model overfit snel en image augmentation geeft ook geen betere resultaten dan kan een voorgetraind model wel toegevoegde waarde hebben.<br />
<!--ID: 1618053215129--></p>

<p>Nadeel Google Colab is het opladen van de data vooraleer het effectieve training begint. Voordeel is wel dat je een gpu kunt gebruiken om te trainen. </p>

<p>10 epochs is weinig. als loss niet begint te zakken na 20 epochs breek af en herbegin. </p>

<p>Q: Hoe komt het dat bij LSTM netwerken de je bij plateaus van de loss functie even geuld moeten hebben ?<br />
A: LSTM netwerken trainen op tijdreeksen en het duurt even vooraller de de verandering in de data gecapteerd wordt door het NN. Hierdoor kan de loss op een plateau geraken en schijnbaar even vastzitten.  Na een paar epochs echter zal het dan toch verder zakken. Dus hier iets meer geduld hebben.<br />
<!--ID: 1618053215138--></p>

<p>Q: Hoe bepaal je of data validatiedata is ? Welke rol speelt de validatiedata bij een NN ?<br />
A: Validatie data is data die je meeft om het model te valideren tijdens de training na elke epoch. Je kan dit doen door enerzijds een validation split meet te geven = deel van trainingsdata wordt dan voor validatie gebruikt ofwel kan je validation data een aparte dataset zijn. Belangrijk hierbij is dat je op de validatiedata feedback krijgt maar dat die resultaten geen <strong>invloedt op de training hebben</strong> !!!<br />
<!--ID: 1618053215143--></p>

<p>Q: Wanneer gebruik je testdata bij een NN ? Wanneer zou je hier een uitzondering op kunnen maken ?<br />
A: Testdata moet je volledig apart houden voor op het einde een evaluatie te doen van je model (na de training en na het kiezen van de beste hyperparameters obv validatieset). Als je echter weinig data hebt dan kan je je testdata als validatiedata gebruiken maar dit is geen good practice !!!<br />
<!--ID: 1618053215150--></p>

<p>Q: Waarom dienen trainingsdata, validatiedata en testdata ?<br />
A: trainingsdata = om weights bij te stellen, validatiedata = om beste hyperparameters te kiezen en testdata = finale test uit te voeren en model in productie kan.<br />
<!--ID: 1618053215155--></p>

<p>je kan imagedatagenerator maken voor je validatiedata en die doorgeven of met imagedatagenerator maak je op voorhand nieuwe dataset en gebruik je die als training/validatieset. </p>

<p>op te zoeken : <code>train_datagen.flow_from_directory(), validation_datagen.flow_from_directory()</code></p>

<p>Q: Wat moet je doen als de loss curve van je NN model grillig verloopt ? Wat geeft dit aan ?<br />
A: Indien de loss-trainingcurve grillig verloopt kan te maken hebben met learningrate die te hoog staat. Je gebruikt misschien optimizer=adam() maar je kan ook hier een learning rate aan meegeven en die wat lager zetten. Hierdoor zal de curve minder grillig zijn.<br />
<!--ID: 1618053215161--></p>

<p>Q: Waarom zou je ReduceLROnPLateau gebruiken ?<br />
A: Als je <a href="https://keras.io/api/callbacks/reduce_lr_on_plateau/">ReduceLROnPLateau()</a> gebruikt kan dit voorkomen dat de loss epoch na epoch hetzelfde blijft.  Hiermee zal de learningrate aangepast worden na een paar epochs (mee te geven als patience) zodat die niet steeds over het optimum zou springen. (Reduce learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.)<br />
<!--ID: 1618053215166--></p>

<p>Q: Hoe komt het dat je gevalideerd model slechter scroot op je trainingsdata dan de loss curve aangeeft ?<br />
A: Als je je getrainde model hebt en dit test mbv je trainingsdata dat kan het zijn dat je niet dezelfde loss en accuracy krijgt als je ziet in de history graph van het model. Dit komt omdat tijdens het training neuronen uitgeschakeld zijn door dropout en dit is niet meer het geval als je het bekomen model na training nog eens test obv je trainingset. In dat geval worden alle neuronen gebruikt om predicties te doen.<br />
<!--ID: 1618053215173--></p>

<p>Q: Wat zijn False Negatives en hoe kan je die verminderen bij NN ?<br />
A: False negatives : treshold hacking = op output van NN een softmax functie gebruiken en daarvan kan je de probabiliteit opvragen voor elke klasse. Op basis daarvan kan je zelf de treshold voor elke klasse bepalen en het aantal False Negatives verminderen.<br />
<!--ID: 1618053215179--></p>

<p>Als je model overfit en je past parameters aan maar loss/accuracy is voor validatieset in beide gevallen hetzelfde dan kan je volgende zaken doen : </p>

<ul>
<li>kijken wat er met je NN gaat gebeuren in de toekomst. Indien er nog trainingsdata bijkomt dan is het overfitte model misschien het beste. </li>
<li>je kan met cross validatie testen en kijken of je hiermee een beter beeld krijgt van de verschillen tussen beide modellen. </li>
</ul>

<p>Q: Wat is de rol van de metric parameter bij het aanmaken van een NN ?<br />
A: Een NN gaat steeds proberen de loss naar beneden te halen via de loss functie (bijv categorical_crossentropy).<br />
<code>model.compile(object, optimizer, loss, *metrics = NULL*,  ...)</code><br />
<strong>De metric heeft echter geen effect op de manier waarop NN getraind wordt.</strong> De metric bepaalt welke scoring je laat zien per epoch. Die scoring gebruik je nadien dan om de beste keuze van de hyperparameters te doen voor je model.<br />
<!--ID: 1618053215184--></p>

<p><a href="https://autokeras.com/">AutoKeras</a> - An AutoML system based on Keras. </p>

<p><a href="https://epistasislab.github.io/tpot/examples/">Tpot</a> - TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.</p>
</div>

      

    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
