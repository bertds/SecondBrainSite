<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- IBM Plex Mono -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">
  <!-- IBM Plex Sans -->
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&display=swap" rel="stylesheet">

  <!-- CSS (uses absolute weblinks to work around relative path issues) -->
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/main.css">
  <link rel="stylesheet" type="text/css" href="https://www.kmaasrud.com/brain/main.css">


</head>

<body>

  <div class="grid">
    <nav>
      <ul>
        <br>
        <li><a href="https://bertds.github.io/SecondBrainSite/">Second Brain</a></li>
        <br>
      </ul>
    </nav>
    <article>
      <div id="content"><p><a href="svm.html">SVM</a><br />
<a href="anki.html">anki</a></p>

<p>Q: Wat is een SVM ?<br />
A: Een SVM is een supervised ML algoritme dat zowel voor classificatie als regressie gebruikt kan worden. Classificatie gebeurt door het vinden van een hyper-plane die een optimale scheiding maakt tussen twee verschillende klasses. Het is een large margin classifier die de marche tss twee klasses zo groot mogelijk maakt bij bepalen van de scheidingslijn tss de klasses.<br />
We kijken naar punten die dichtst bij elkaar liggen en daar proberen een scheidingslijn te kiezen die zover mogelijk van beide verwijderd is.<br />
<!--ID: 1610788995176--></p>

<p>Q: Hoe classicifeert een SVM ?<br />
A: Gebruik volgende stappen : </p>

<ul>
<li>Zoek scheidingslijnen die de trainingset zo goed mogelijk scheiden</li>
<li>Kies de scheidingslijn die de grootste afstand (margin) heeft tot de punten die er het dichtst bij gelegen zijn.</li>
<li>De dichtstbij gelegen punten noemen we de support vectors</li>
<li>SVM = Large margin classifier<br />
<!--ID: 1610788995230--></li>
</ul>

<p>Q: Wat als de perfecte lineaire scheiding niet mogelijk is bij een SVM ?<br />
A: Antwoord: Werken met een regularisatie parameter C<br />
Afweging tussen correcte classificatie op training set en een grote marge tussen de klasses (large margin).<br />
    - Grote C-waarde: constraints zijn moeilijk te negeren ⇒ smalle marge ⇒ zo min mogelijk classifier fouten<br />
    - Kleine C-waarde: constraints kunnen makkelijker genegeerd worden ⇒ brede marge<br />
<!--ID: 1610788995247--></p>

<p>Q: Wat bij niet-lineair scheidbare gegevens bij een SVM ?<br />
A: Oplossing: transformeer de data naar een hogere dimensie gevolgd door lineaire scheiding of  Projecteer de data in een hogere dimenensie en probeer lineair te scheiden (met een kernel)<br />
<!--ID: 1610788995258--></p>

<p>Q: Welke kernels kan je gebruiken bij een SVM ?<br />
A: Meest gebruikte kernels:</p>

<ul>
<li><strong>RBF - Radial Basis Function (Gaussiaanse kernel)</strong></li>
<li>Polynomial kernel  </li>
<li>Histogram kernel  </li>
<li><strong>Lineaire kernel = SVM zonder kernel</strong><br />
<!--ID: 1610788995267--></li>
</ul>

<p>Q: Wat doet de parameter gamma bij een SVM en hoe zie je het effect ervan ?<br />
A: Parameter gamma regelt de breedte van de RBF kernels</p>

<ul>
<li>Kleine gamma ⇒ brede RBF kernels. Te kleine gamma leidt ertoe dat het model de complexiteit van het model niet kan capteren (underfitting) (eenvoudiger model)</li>
<li>Grote gamma ⇒ smalle RBF kernels. Te grote gamma leidt tot overfitting Bij gebruik van een RBF kernel: feature scaling (= normalisatie) toepassen (complexer model)<br />
<!--ID: 1610788995274--></li>
</ul>

<p>Q: Wat mag je zeker niet vergeten bij SVM als je RBF-kernels gebruikt ?<br />
A: feature scaling is toepassen ! de RBF-kernels zijn rond en als de features op verschillende schalen staan heb je elipsvormige kernels nodig.<br />
<!--ID: 1610788995279--></p>

<p>Q: Waarom zou je een SVM verkiezen ? Wat zijn de mogelijke nadelen ?<br />
A: - Kan zowel gebruikt worden voor regressie als classificatie (en zelfs clustering)<br />
    Bij classificatie kan je wel niet opvragen hoe zeker het model is van keuze classificatie !</p>

<ul>
<li>Werkt goed op kleine datasets (in tegenstelling tot neurale netwerken en deeplearning)</li>
<li>Is nog altijd effectief wanneer het aantal features groter is dan het aantal training samples</li>
<li>Het werkt goed bij een groot aantal features (high dimensional space)</li>
<li>Gebruikt niet alle training examples tijdens training ⇒ geheugenefficiënt</li>
<li>Geen lokale minima/optima, maar globaal optimum</li>
<li>Gevoelig voor uitschieters zeker als ze in de buurt komen van de scheidingslijn want dan wordt uitschieter deel van supportvector en wordt scheidingslijn aangepast. Als je de marge echter groter neemt dan heeft uitschieter mindern een invloed op de scheidingslijn.<br />
Nadeel : als je veel kernels hebt, heb je veel rekenkracht nodig.<br />
<!--ID: 1610788995296--></li>
</ul>

<p>Q: Wanneer zou je SVM gebruiken en wanneer Logistic Regression ?<br />
A: Wanneer welke classifier kiezen?</p>

<ul>
<li>Wanneer het aantal features groot is ten opzichte van het aantal training samples: gebruik logistic regression of SVM zonder kernel (= lineaire kernel)</li>
<li>Wanneer het aantal features klein is en het aantal training samples behoorlijk: gebruik SVM met RBF kernel</li>
<li>Bij een klein aantal features met een groot aantal training samples: creëer meer features en gebruik logistic regression of SVM zonder kernel (= lineaire kernel)<br />
<!--ID: 1610788995304--></li>
</ul>

<p>Q: Als je valdatie wil gebruiken om je model te trainen, hoe splits je je data dan op ? Wat zijn de voor/nadelen als je je data in andere verhoudingen opsplitst ?<br />
A: Je splitst je data op in :</p>

<ul>
<li>Training data: om model mee te trainen</li>
<li>Validation data: tuning van hyper parameters en model selection</li>
<li>Test data: uiteindelijke test van het best gevalideerde model op nog nooit geziene data<br />
Bij het trainen splits je je data op in validatiedata en trainingsdata. Als je veel trainingsdata kiest (en dus minder validatiedata) dan is het beter getraind maar is de validatie minder betrouwbaar. Omgekeerd is het model minder goed getraind/slechtere accuracy maar wel beter gevalideert.<br />
<!--ID: 1610788995317--></li>
</ul>

<p>Q: Welke classifier zou je verkiezen ? Bespreek<br />
 <img src="SVMwelke.png" alt="SVMwelke.png" /><br />
A: Bespreking : </p>

<ul>
<li>Beide scheiden de training data perfect  </li>
<li>Het gaat er niet om welke er best presteert op de training data, maar wel op de test data</li>
<li>De rechtse classifier is meer robuust<br />
<!--ID: 1610789949167--></li>
</ul>

<p>Q: Een support vector machine werd 3 keer getraind met een RBF kernel, telkens met verschillende gamma waarden. De C-waarde was telkens hetzelfde. Rangschik de onderstaande plots (A, B, C) van kleine gamma waarde naar grote gamma waarde.<br />
<img src="gammeRBFquestion.png" alt="gammeRBFquestion.png" /><br />
A: A &lt; C &lt; B<br />
<!--ID: 1610790423085--></p>

<p>Q: Wat is K-fold cross validation ? Wanneer gebruik je het ? Wat is een nadeel ?<br />
A: Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.<br />
The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into.<br />
_Voor verschillende K-waarden kan je andere resultaten krijgen dus interessant om dat ook te laten wisselen._<br />
Zeker gebruiken als je weining trainingsdata hebt tov het aantal features<br />
Zoeken naar optimale hyperparameters<br />
Nadeel : testdata voor model (hier is dat de validatiedata) lekt door in model omdat je traint op alle data.<br />
<!--ID: 1611169920510--></p>

<p>Q: K-folds vs RandomSplit wat is het verschil  ?<br />
A: K folds comprises in creating K subsamples. Because you now have a more significant number of samples (instead of 2), you can separate one of the subsamples for testing and the remaining subsamples for training, do this for every possible combination of testing/training folds and average the results. This is known as <strong>cross-validation</strong>. Doing K-fold cross-validation is like doing a (not random) split k times, and then averaging. _A small sample might not benefit from k-fold cross-validation, while a large sample usually always do benefit from cross-validation._ A <strong>random split is a more efficient (faster)</strong> way of estimating, but _might be more prone to sampling bias than k-fold cross-validation._ Combining stratification and random split is an attempt to have an effective and efficient sampling strategy that preserves label distribution.<br />
<!--ID: 1611169972229--></p>

<p>Q: Wat is ShuffleSplit ?<br />
A: In ShuffleSplit, <strong>the data is shuffled every time</strong>, and then split. This means <strong>the test sets may overlap</strong> between the splits.<br />
<!--ID: 1611169921199--></p>

<p>Q: Wat is StratifiedKFold ?<br />
A: StratifiedKFold is a variation of KFold. First, <strong>StratifiedKFold shuffles your data, after that splits the data into n_splits parts and Done.</strong> Now, it will use each part as a test set. Note that it only and always shuffles data one time before splitting.<br />
With shuffle = True, the data is shuffled by your random_state. Otherwise, the data is shuffled by np.random (as default). For example, with n_splits = 4, and your data has 3 classes (label) for y (dependent variable). 4 test sets cover all the data without any overlap.<br />
<!--ID: 1611169921220--></p>

<p>Q: Wat is StratifiedShuffleSplit ?<br />
A: On the other hand, StratifiedShuffleSplit is a variation of ShuffleSplit. First, StratifiedShuffleSplit shuffles your data, and then it also splits the data into n_splits parts. However, it's not done yet. After this step, StratifiedShuffleSplit picks one part to use as a test set. Then it repeats the same process n_splits - 1 other times, to get n_splits - 1 other test sets. Look at the picture below, with the same data, but this time, the 4 test sets do not cover all the data, i.e there are overlaps among test sets.<br />
<!--ID: 1611169921238--></p>

<p>Q: Verschil StratifiedKFold en StratifiedShuffleSplit ? Wat betekent Stratified ?<br />
A: So, the difference here is that StratifiedKFold just shuffles and splits once, therefore the test sets do not overlap, while StratifiedShuffleSplit shuffles each time before splitting, and it splits n_splits times, the test sets can overlap.<br />
Note: the two methods uses "stratified fold" (that why "stratified" appears in both names). It means each part preserves the same percentage of samples of each class (label) as the original data.<br />
<!--ID: 1611169921253--></p>

<p>Q: Wat is Grid search ? Voor/nadelen ?<br />
A: per parametervariatie en cross validatie :</p>

<ul>
<li>veel modellen moeten getraind worden en gevalideerd worden</li>
<li>veel rekenkracht nodig<br />
<!--ID: 1611169921276--></li>
</ul>

<p>Q: Wat is Random Search ? Voor/nadelen ?<br />
A: willekeurig een aantal combinaties proberen<br />
10 combinaties en cross validatie :</p>

<ul>
<li>minder modellen -> minder rekentijd nodig</li>
<li>geen tijd verliezen aan nodeloos rekenwerk voor bepaalde hyperparameters waarden.<br />
<!--ID: 1611169921299--></li>
</ul>

<p>Q: Hoe rekentijd verbeteren ? oa bij GridSearch<br />
A: Hyperparameterwaarden niet lineair laten varieren maar exponentieel of logaritmisch<br />
<!--ID: 1611169921319--></p>

<p>Q: Split (Holdout) vs RandomSplit : wat is het en wat zijn de verschillen?<br />
A: Split vs Random Split. <strong>A split is just a split</strong>, usually for the purpose of having separate training and testing subsamples. But taking the first X% for a subsample and the remaining for another subsample _might not be a good idea because it can introduce very high bias._ There is where <strong>random split</strong> comes into play, by <strong>introducing randomness for the subsampling</strong>.<br />
<!--ID: 1611169921336--></p>
</div>

      <div class="backlinks">

<ul>
<li><a href="support-vector-machines.html">Support Vector Machines</a></li>
</ul>

</div>


    </article>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
   mermaid.initialize();
  </script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>

  <!-- Parsing single dollar signs -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
          {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
        ]
    });
    });
  </script>

  <!-- Syntax highlighting through highlight.js -->
  <link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/styles/default.min.css">
  <script src="https://unpkg.com/@highlightjs/cdn-assets@10.4.0/highlight.min.js"></script>

  <script>
    // Ignore highlighting of mermaid
    hljs.configure({noHighlightRe: /^mermaid$/});
    hljs.initHighlightingOnLoad();
  </script>

</body>

</html>
